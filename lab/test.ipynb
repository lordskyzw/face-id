{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video stream.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def show_camera_feed():\n",
    "    # Replace with your camera's stream URL\n",
    "    camera_stream_url = '192.168.100.65'\n",
    "\n",
    "    # Create a VideoCapture object\n",
    "    cap = cv2.VideoCapture(camera_stream_url)\n",
    "\n",
    "    # Check if the camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream.\")\n",
    "        return\n",
    "\n",
    "    # Read and display frames from the camera\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imshow('Camera Feed', frame)\n",
    "            # Press 'q' to exit the window\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "show_camera_feed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://192.168.100.65')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'hi': 'hello'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "res = requests.get('https://face-id.up.railway.app/test')\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(faceobjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dataset/Tarmica/image_1c13626ce0d94befac4135b660308117.jpg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceobjs[0].iloc[0, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        # Parse the incoming request to get the image data\n",
    "        image_data = event['body']\n",
    "        \n",
    "        # Detect the face in the image using DeepFace\n",
    "        face_detected = DeepFace.extract_faces(image_data, enforce_detection=False)\n",
    "        \n",
    "        if face_detected[0]['confidence']>0.7:\n",
    "            # If a face is detected, search for the face in the S3 bucket\n",
    "            db_path = \"s3://chumbucketzw/images/\"\n",
    "            recognition_result = DeepFace.find(img_path=image_data, db_path=db_path, enforce_detection=False)\n",
    "            faces_df = recognition_result[0]\n",
    "            tup = recognition_result[0].shape\n",
    "            \n",
    "            if tup[0]>1:\n",
    "                identity = faces_df.iloc[0,0]  # Extract the person's name\n",
    "                person_name = identity.split('/')[-2]\n",
    "                return {\n",
    "                    'statusCode': 200,\n",
    "                    'body': json.dumps(f'Person identified: {person_name}')\n",
    "                }\n",
    "            else:\n",
    "                # Face not recognized\n",
    "                return {\n",
    "                    'statusCode': 200,\n",
    "                    'body': json.dumps('Unknown human detected')\n",
    "                }\n",
    "        else:\n",
    "            # No face detected\n",
    "            return {\n",
    "                'statusCode': 200,\n",
    "                'body': json.dumps('No face is in the image')\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f'Error processing the image: {str(e)}')\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
